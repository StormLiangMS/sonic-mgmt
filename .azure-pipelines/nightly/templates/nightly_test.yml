parameters:
  - name: TESTBED_NAME
    type: string

  - name: TESTBED_FILE
    type: string
    default: testbed.yaml
    values:
      - testbed.csv
      - testbed.yaml

  # Upgrade parameters
  - name: IMAGE_URL
    type: string
    default: ""
  - name: ALWAYS_INSTALL_NEW_IMAGE
    type: boolean
    default: true
  - name: UPGRADE_TYPE
    type: string
    default: sonic
    values:
      - sonic
      - onie
  - name: PAUSE_TIME
    type: number
    default: 0

  # Deploy parameters
  - name: ENABLE_DATAACL
    type: boolean
    default: true

  # Test Parameters
  - name: PY_SAITHRIFT_URL
    type: string
    default: ""
  - name: PTF_PORTMAP
    type: string
    default: ""
  - name: EXTRA_PARAMS
    type: string
    default: ""
  - name: TESTBED_SPECIFIC
    type: string
    default: ""
  - name: SKIP_SCRIPTS
    type: string
    default: "vrf/test_vrf.py vrf/test_vrf_attr.py mvrf/test_mgmtvrf.py"

stages:

  - stage: Test
    jobs:

      - job: NightlyTest
        pool: nightly
        timeoutInMinutes: 1800  # 30 hours
        variables:
          - group: TBSHARE_SECRETS
          - group: KUSTO_SECRETS

        steps:

          - task: AzureKeyVault@1
            displayName: Get Secrets
            inputs:
              azureSubscription: 'Network Production Environment -- SONiC(9355ef17-3aa2-493a-94ab-a43a9bf8cd70)'
              KeyVaultName: 'SONiC'
              SecretsFilter: '*'
              RunAsPreJob: false

          - task: Bash@3
            displayName: Save Secrets
            inputs:
              targetType: 'inline'
              script: |
                # Download secrets.json from Azure Key Vault
                # The AzureKeyVault task automatically set variable for each secret found in key vault
                # Secrets available: nm-secrets, ansible-vault-passwd
                echo '$(nm-secrets)' > ansible/group_vars/all/secrets.json
                echo '$(ansible-vault-passwd)' > ansible/password.txt

                # decrypt the secret file
                md5sum ansible/group_vars/all/secrets.json
                ansible-vault decrypt ansible/group_vars/all/secrets.json --vault-password-file=ansible/password.txt

          - task: PythonScript@0
            displayName: Parse Testbed Info
            inputs:
              scriptSource: 'inline'
              script: |
                from __future__ import print_function
                import os, imp, sys

                testbed_module = imp.load_source('testbed', 'tests/common/testbed.py')
                testbed_name = os.environ.get('TESTBED_NAME')
                testbed_file = os.environ.get('TESTBED_FILE')
                tbinfo = testbed_module.TestbedInfo('ansible/{}'.format(testbed_file))
                target_testbed = tbinfo.testbed_topo.get(testbed_name, None)
                if not target_testbed:
                    print('Testbed {} not found!'.format(testbed_name))
                    sys.exit(1)

                print('Basic info of testbed {}:'.format(testbed_name))
                print('    INVENTORY_NAME={}'.format(target_testbed['inv_name']))
                print('     TOPOLOGY_NAME={}'.format(target_testbed['topo']['name']))
                print('     TOPOLOGY_TYPE={}'.format(target_testbed['topo']['type']))

                # Below code can create dynamic azure pipeline variables
                # Reference: https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#set-a-job-scoped-variable-from-a-script
                print('##vso[task.setvariable variable=INVENTORY_NAME;]{}'.format(target_testbed['inv_name']))
                print('##vso[task.setvariable variable=TOPOLOGY_NAME;]{}'.format(target_testbed['topo']['name']))
                print('##vso[task.setvariable variable=TOPOLOGY_TYPE;]{}'.format(target_testbed['topo']['type']))
            env:
              TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
              TESTBED_FILE: ${{ parameters.TESTBED_FILE }}

          - task: PythonScript@0
            displayName: Lock Testbed
            inputs:
              scriptSource: 'filePath'
              scriptPath: ./.azure-pipelines/nightly/templates/lock_release.py
              arguments: lock
            env:
                TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
                TBSHARE_AAD_CLIENT_ID: $(TBSHARE_AAD_CLIENT_ID)
                TBSHARE_AAD_CLIENT_SECRET: $(TBSHARE_AAD_CLIENT_SECRET)

          - task: Bash@3
            displayName: "Upgrade Image"
            inputs:
              targetType: 'inline'
              script: |
                set -x

                if [[ -z "$IMAGE_URL" ]]; then
                    echo "Skipping image upgrading ..."
                    exit 0
                fi

                cd ansible

                if [[ "$ALWAYS_INSTALL_NEW_IMAGE" == "true" && "$UPGRADE_TYPE" == "sonic" ]]; then
                    ANSIBLE_FORCE_COLOR=true ansible-playbook upgrade_sonic.yml \
                        -i $(INVENTORY_NAME) \
                        -e testbed_name=${{ parameters.TESTBED_NAME }} \
                        -e image_url=$IMAGE_URL.PREV.1 \
                        -e upgrade_type=$UPGRADE_TYPE \
                        --vault-password-file password.txt \
                        -e pause_time=60 -vv || true
                fi
                ANSIBLE_FORCE_COLOR=true ansible-playbook upgrade_sonic.yml \
                    -i $(INVENTORY_NAME) \
                    -e testbed_name=${{ parameters.TESTBED_NAME }} \
                    -e image_url=$IMAGE_URL \
                    -e upgrade_type=$UPGRADE_TYPE \
                    --vault-password-file password.txt \
                    -e pause_time=$PAUSE_TIME -vv

                sleep 180
            env:
              IMAGE_URL: ${{ parameters.IMAGE_URL }}
              ALWAYS_INSTALL_NEW_IMAGE: ${{ parameters.ALWAYS_INSTALL_NEW_IMAGE }}
              UPGRADE_TYPE: ${{ parameters.UPGRADE_TYPE }}
              PAUSE_TIME: ${{ parameters.PAUSE_TIME }}

          - task: Bash@3
            displayName: Deploy Minigraph
            inputs:
              targetType: 'inline'
              script: |
                set -x

                CONFIG_PARAMS=""

                if [[ "$ENABLE_DATAACL" == "true" ]]; then
                  CONFIG_PARAMS="$CONFIG_PARAMS -e enable_data_plane_acl=$ENABLE_DATAACL"
                fi
                cd ansible

                ./testbed-cli.sh restart-ptf $TESTBED_NAME password.txt
                ./testbed-cli.sh deploy-mg $TESTBED_NAME $INVENTORY_NAME password.txt $CONFIG_PARAMS
                sleep 180
            env:
              TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
              INVENTORY_NAME: $(INVENTORY_NAME)
              ENABLE_DATAACL: ${{ parameters.ENABLE_DATAACL }}

          - task: Bash@3
            displayName: Run Tests
            inputs:
              targetType: 'inline'
              script: |
                set -x

                BASE_PATH=`pwd`
                PARAMS="--allow_recover --showlocals --assert plain -rav --collect_techsupport False --deep_clean"

                if [[ -n $PY_SAITHRIFT_URL ]]; then
                    PARAMS="$PARAMS --py_saithrift_url=$PY_SAITHRIFT_URL"
                fi

                if [[ -n $PTF_PORTMAP ]]; then
                    PARAMS="$PARAMS --ptf_portmap=$PTF_PORTMAP"
                fi

                if [[ -n $EXTRA_PARAMS ]]; then
                    PARAMS="$PARAMS $EXTRA_PARAMS"
                fi

                rm -fr results     # Clear any possible collected results of previous run

                cd tests

                # '$(INVENTORY_NAME)' and '$(TOPOLOGY_TYPE)' are dynamic variables generated in step_parse_testbed_info.yml
                ./run_tests.sh -n ${{ parameters.TESTBED_NAME }} \
                    -s "$SKIP_SCRIPTS" \
                    -i $BASE_PATH/ansible/$(INVENTORY_NAME),$BASE_PATH/ansible/veos \
                    -m individual \
                    -t $(TOPOLOGY_TYPE),any -r \
                    -e "$EXTRA_PARAMS" $TESTBED_SPECIFIC \
                    $TEST_CONTROL

                exit 0
            env:
              PY_SAITHRIFT_URL: ${{ parameters.PY_SAITHRIFT_URL }}
              PTF_PORTMAP: ${{ parameters.PTF_PORTMAP }}
              EXTRA_PARAMS: ${{ parameters.EXTRA_PARAMS }}
              TESTBED_SPECIFIC: ${{ parameters.TESTBED_SPECIFIC }}
              SKIP_SCRIPTS: ${{ parameters.SKIP_SCRIPTS }}

          - publish: tests/logs
            displayName: "Archive test logs"
            artifact: ${{ parameters.TESTBED_NAME}}.nightly.log@$(System.JobAttempt)
            condition: always()

          - task: PublishTestResults@2
            displayName: Publish test results
            inputs:
              testResultsFiles: 'tests/logs/**/*.xml'
              testRunTitle: ${{ parameters.TESTBED_NAME}}.nightly
            condition: always()

          - task: PythonScript@0
            displayName: Release Testbed
            inputs:
              scriptSource: 'filePath'
              scriptPath: ./.azure-pipelines/nightly/templates/lock_release.py
              arguments: release
            env:
                TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
                TBSHARE_AAD_CLIENT_ID: $(TBSHARE_AAD_CLIENT_ID)
                TBSHARE_AAD_CLIENT_SECRET: $(TBSHARE_AAD_CLIENT_SECRET)
            condition: always()

          - task: CopyFiles@2
            displayName: Collect result files
            inputs:
              Contents: |
                tests/logs/**/*.xml
                tests/logs/platform_tests/test_*_reboot*.json
              TargetFolder: results
              CleanTargetFolder: true
            condition: succeededOrFailed()

          - task: Bash@3
            displayName: Upload Test Results
            inputs:
              targetType: 'inline'
              script: |
                set -x
                echo "Activate python3 virtual environment"
                source /var/AzDevOps/env-python3/bin/activate

                cd test_reporting
                pip3 install -r requirements.txt

                python3 junit_xml_parser.py -d ../results -o tr.json

                # temporary workaround to allow reboot timing data upload
                # After recent test change, the file names get DUT name in them
                # A more permanent fix is needed in report_uploader.py to accept file names with DUT name
                mv ../results/test_fast_reboot*_summary.json ../results/test_fast_reboot_summary.json || true
                mv ../results/test_fast_reboot*_report.json ../results/test_fast_reboot_report.json || true
                mv ../results/test_warm_reboot*_summary.json ../results/test_warm_reboot_summary.json || true
                mv ../results/test_warm_reboot*_report.json ../results/test_warm_reboot_report.json || true

                report_upload_files="../results $(find ../results -type f -iname 'test_*_reboot*.json')"

                python3 report_uploader.py -c "test_result" -e "$(Build.DefinitionName)#$(Build.BuildId)" $report_upload_files SonicTestData
            condition: succeededOrFailed()
            env:
              TEST_REPORT_INGEST_KUSTO_CLUSTER: $(TEST_REPORT_INGEST_KUSTO_CLUSTER)
              TEST_REPORT_AAD_TENANT_ID: $(TEST_REPORT_AAD_TENANT_ID)
              TEST_REPORT_AAD_CLIENT_ID: $(TEST_REPORT_AAD_CLIENT_ID)
              TEST_REPORT_AAD_CLIENT_KEY: $(TEST_REPORT_AAD_CLIENT_KEY)
